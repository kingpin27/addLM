{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpHT7HRKgo7f"
      },
      "source": [
        "# addGPT\n",
        "\n",
        "LLM to do basic addition using reasoning of two unsigned numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Mo413YhK_e"
      },
      "source": [
        "## Dataset generation\n",
        "\n",
        "1. Sample two random numbers from uniform distribution with range 0 to 99999999\n",
        "\n",
        "2. Generate step by step addition procedure for adding two numbers in text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr1On0fGhyoB",
        "outputId": "6ef4e64f-b493-4a43-c0ae-d76fd7fafb9a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZsZVd6O5pA0X",
        "outputId": "fcc12b05-e25c-4fef-a7b7-b4d5e44bacbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<reason><digit_sum>5</digit_sum><carry>0</carry><digit_sum>5</digit_sum><carry>0</carry><digit_sum>1</digit_sum><carry>0</carry></reason>'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generateReasoningToken(i,j):\n",
        "  rt=\"<reason>\"\n",
        "  while i>0 or j>0:\n",
        "    p = i%10\n",
        "    q = j%10\n",
        "    sum = p+q\n",
        "    rt += \"<digit_sum>\" + str(sum%10) + \"</digit_sum>\"\n",
        "    rt += \"<carry>\" + str(int(sum/10)) + \"</carry>\"\n",
        "    i = int(i/10)\n",
        "    j = int(j/10)\n",
        "  return rt + \"</reason>\"\n",
        "\n",
        "generateReasoningToken(100, 55)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LkLeTgtVlInQ"
      },
      "outputs": [],
      "source": [
        "A = np.random.uniform(0, 99999999, 100000).round().astype(int)\n",
        "B = np.random.uniform(0, 99999999, 100000).round().astype(int)\n",
        "\n",
        "Input = np.char.add(np.char.add(np.char.add(np.char.add(\"<prompt>\",A.astype(str)), '+'), B.astype(str)),\"</prompt>\")\n",
        "Reason = np.array([generateReasoningToken(i,j) for i,j in zip(A,B)])\n",
        "Output = np.char.add(\"<answer>\",np.char.add((A+B).astype(str), \"</answer>\"))\n",
        "\n",
        "Examples = np.char.add(Input,np.char.add(Reason,Output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LTiVoqA8u25"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aqJZMitxu_zs"
      },
      "outputs": [],
      "source": [
        "dictionary = {\n",
        "    \"<nop/>\":0,\n",
        "    \"<prompt>\":1,\n",
        "    \"</prompt>\":2,\n",
        "    \"<answer>\":3,\n",
        "    \"</answer>\":4,\n",
        "    \"<reason>\":5,\n",
        "    \"</reason>\":6,\n",
        "    \"<digit_sum>\":7,\n",
        "    \"</digit_sum>\":8,\n",
        "    \"<carry>\":9,\n",
        "    \"</carry>\":10,\n",
        "    \"0\":11,\n",
        "    \"1\":12,\n",
        "    \"2\":13,\n",
        "    \"3\":14,\n",
        "    \"4\":15,\n",
        "    \"5\":16,\n",
        "    \"6\":17,\n",
        "    \"7\":18,\n",
        "    \"8\":19,\n",
        "    \"9\":20,\n",
        "    \"+\": 21\n",
        "}\n",
        "\n",
        "ReverseIdToToken = {v:k for k,v in dictionary.items()}\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'<nop/>|[0-9]|\\+|<prompt>|</prompt>|<answer>|</answer>|<reason>|<digit_sum>|<carry>|</reason>|</digit_sum>|</carry>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F-Xd0Bx_xuti"
      },
      "outputs": [],
      "source": [
        "ExampleTokens = list(map(tokenizer.tokenize, Examples))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pyVxi3Zx0c7p"
      },
      "outputs": [],
      "source": [
        "TokenIds = [[dictionary[token] for token in example] for example in ExampleTokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KWRajNzN0mr5"
      },
      "outputs": [],
      "source": [
        "def create_training_examples(token_ids, context_length):\n",
        "  training_examples = []\n",
        "  for example in token_ids:\n",
        "    for i in range(0, len(example)):\n",
        "      context = example[max(i-context_length+1, 0):i+1]\n",
        "\n",
        "      if len(context)<context_length:\n",
        "        filler = [0]*(context_length-len(context))\n",
        "        # print(len(filler))\n",
        "        filler.extend(context)\n",
        "        context=filler\n",
        "          # context.extend([0]*(context_length-len(context)))\n",
        "      # print(len(context))\n",
        "      assert len(context)==context_length\n",
        "      training_examples.append(context)\n",
        "\n",
        "  return np.array(training_examples)\n",
        "\n",
        "context_length = 65\n",
        "training_examples = create_training_examples(TokenIds, context_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-gUTNAK1Uw8",
        "outputId": "d3248dbd-0d6f-458f-9119-5aab90583802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training examples: (7921284, 65)\n",
            "First training example: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  1 12 13 19 15 16 13 12 15 21 15 14 13 14 17 12\n",
            " 14 15  2  5  7 19  8  9 11 10  7 15  8  9 11 10  7]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of training examples: {training_examples.shape}\")\n",
        "print(f\"First training example: {training_examples[32873]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "FLMOeqHU2lmw",
        "outputId": "707557c3-f30a-49a2-a833-e07d1add5680"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor(training_examples, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kjO0zWJ76eDI"
      },
      "outputs": [],
      "source": [
        "torch.save(data, 'data.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfghyKyG9Phw",
        "outputId": "2134fd9b-812b-4756-9de9-7164590c233e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([7921284])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = torch.randperm(data.shape[0])\n",
        "idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5ob1dPiG-D8y"
      },
      "outputs": [],
      "source": [
        "X = data[idx,0:64]\n",
        "Y = data[idx, 1:65]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwy9R8qv_uLY",
        "outputId": "87e6dfdf-a7dc-43c3-904a-ca7d2f6a2ec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  1., 19., 18., 18., 18., 14., 18., 14., 21., 14.,\n",
              "        15., 18., 14., 18., 15., 20., 11.,  2.])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW7cDHWpAIS8",
        "outputId": "a6d1ffa6-61dd-4989-f5fc-9f5fb4cf40e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "         0.,  0.,  0.,  1., 19., 18., 18., 18., 14., 18., 14., 21., 14., 15.,\n",
              "        18., 14., 18., 15., 20., 11.,  2.,  5.])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rvWv0tx1AaG1"
      },
      "outputs": [],
      "source": [
        "torch.save(X, 'X.pt')\n",
        "torch.save(Y, 'Y.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhaYZoPcAxfR"
      },
      "source": [
        "## Model\n",
        "\n",
        "Transformer architecture with context window of 64 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uK5tCsTpCU0v"
      },
      "outputs": [],
      "source": [
        "transformer = torch.nn.Transformer()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
